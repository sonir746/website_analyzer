{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE-REQUIREMENTS\n",
    " {run only ones for setup}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncomment blow cell and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics\n",
    "# !pip install pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to work with GPU also run blow cell (before run uncomment it) this file may be 2.5GB or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 33.2ms\n",
      "Speed: 0.0ms preprocess, 33.2ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 20.4ms\n",
      "Speed: 0.0ms preprocess, 20.4ms inference, 5.4ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 19.3ms\n",
      "Speed: 0.0ms preprocess, 19.3ms inference, 6.8ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 34.2ms\n",
      "Speed: 0.0ms preprocess, 34.2ms inference, 10.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 34.8ms\n",
      "Speed: 0.0ms preprocess, 34.8ms inference, 8.5ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 33.1ms\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 33.7ms\n",
      "Speed: 0.0ms preprocess, 33.7ms inference, 8.5ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 37.3ms\n",
      "Speed: 0.0ms preprocess, 37.3ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 32.1ms\n",
      "Speed: 4.5ms preprocess, 32.1ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 13.8ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 38.5ms\n",
      "Speed: 0.0ms preprocess, 38.5ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 32.7ms\n",
      "Speed: 0.0ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 35.7ms\n",
      "Speed: 0.0ms preprocess, 35.7ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 16.3ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 36.5ms\n",
      "Speed: 0.0ms preprocess, 36.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 32.5ms\n",
      "Speed: 6.6ms preprocess, 32.5ms inference, 8.1ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 37.1ms\n",
      "Speed: 0.0ms preprocess, 37.1ms inference, 5.5ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 34.4ms\n",
      "Speed: 0.0ms preprocess, 34.4ms inference, 9.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 34.1ms\n",
      "Speed: 4.0ms preprocess, 34.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 29.2ms\n",
      "Speed: 3.6ms preprocess, 29.2ms inference, 11.1ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 32.0ms\n",
      "Speed: 0.0ms preprocess, 32.0ms inference, 13.8ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 33.9ms\n",
      "Speed: 0.3ms preprocess, 33.9ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 34.4ms\n",
      "Speed: 5.7ms preprocess, 34.4ms inference, 8.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\WORK\\Documents\\website_analyzer\\source\\images\\input_4.png: 224x128 2 texts, 6 buttonss, 2 imagess, 1 input fields, 1 navigations dots, 39.4ms\n",
      "Speed: 2.6ms preprocess, 39.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# give the path of model \n",
    "model = YOLO('model/model.pt') \n",
    "\n",
    "# give the path of image\n",
    "img= 'source/images/input_4.png'\n",
    "\n",
    "while True: \n",
    "    # predict the image\n",
    "    results = model.predict(source=img,save=True, show=True, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')) \n",
    "    \n",
    "    #press ESC or 'q' or 'Q'  and hold a second for exit window\n",
    "    if cv2.waitKey(1)==ord(\"q\") or cv2.waitKey(1)==ord(\"Q\") or cv2.waitKey(1)==27:\n",
    "        break\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list > requirement.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
